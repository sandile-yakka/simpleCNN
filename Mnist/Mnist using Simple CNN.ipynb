{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN for Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Plain\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import torch.nn as nn\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt \n",
    "%xmode plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "## MNist dataset\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_target) = next(examples)\n",
    "\n",
    "print(example_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAELCAYAAACbGIJJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHTlJREFUeJzt3XmwVOWZx/HfAyIgJIiAKwKCIwkaRYSoCC4Jo4igKBoJjnGpEU3UWNGAUbQQI6OFM6aMAdSqodyiMeISVDSQDIKOaIQSjApJgcPiCCNXFlkjyzt/dHM879Hue27f7n7Pvff7qbrl+/R7lqcvr/30We57zDknAABCaRY6AQBA00YhAgAERSECAARFIQIABEUhAgAERSECAATVIAqRmd1hZk9UeB+nm9nHldxHLfsfZGYrQu2/KWAcob4YQ5WRqhCZ2Ugze9vMtprZp/n2T8zMKp1gaGbWxcy2xH5c/vewNx5Ywjb3yW+nWxnz/Fsiz11m9ny5tl8OjKMGMY5+ZWbLzGyzmS0xs0vKte1yYAw1iDH0QzObb2bbzOxPadaptRCZ2U2S7pd0r6SDJR0k6RpJp0jat8A6zVNnnXHOuVXOubZ7f/IvHxd77fXkOiHev3OuZyzHb0r6RNIz1c6jEMZRwxhHkrZIOkdSO0lXSppsZt8NkMdXMIYazBj6TNJ9yv07peOcK/ij3GDcKmlELcs9ImmqpJn55Qfl131M0jpJKyXdJqlZfvk7JD0RW7+bJCdpn3x8hKS5kjZLmi3pN/Hl0/zEtnmZpFWSaiSNi/W3zue9QdKHksZI+jjFdp2kIxOvPSFpsqRX8+//dElvSLo8tsy/Snot334zv52tyv2PPyL/O1shaWz+d/aJpB/V5T3H9vV9SZsktS5l/XL/MI4a5jjK72OmpBsYQ4yhEv7NrpH0pzTL7qPiTpbUUtIfallOkkZJGiJpqHLfTh5WbgB0l9RB0ixJayT9Z4ptPSlpvqQzJZ0o6eV4Dma2sci69zjn7onFAyT1lHSUpL+Y2XPOuSWSxkvqkf9pI+mVFHkVs/f9vy2pRS3Lnippp6SjnXMrpNx5WUmdlRuUh0o6W9JTZvaCc+5zM7tU0s+cc31S5HKZpGecc9tLeiflxzhKLzPjyMz2k9RXuW+3oTGG0svMGEqtlor2L5LWJl57U9JGSdslnRr7FvJYbJnmkv4hqVfstav1ZRW+QwW+hUjqImmXpDax/idV+reQzrHX/iJpZL79kaTBsb7Rqt+3kGmJ14p9C9knv51usf5Byn0jaR57bb2kvnV8323z2xlQ128wlfphHDXIcWT5fF4KPX4YQw12DKU+IqrtGtFnkjqaWXTk5Jzr75zbP98XX391rN1RuW8iK2OvrZR0WC37k3IVeINzbmti3VKtjbW3KfdBvXc/8Zzrsw8ltlWqGufc7lgczzetC5X7H/aNMuRTLoyj9LIyju5T7pv7D8uQTzkwhtLLyhhKrbZCNF+5bxPnpdhWfBrvGuUO97rGXusi6X/z7a2S9ov1HRxrr5HU3szaJNaNJO4cSf7cmiLXvfs5vNA+SuAScbH3mFy2nC5T7nx4ljCO0gs+jsxsonLXGQc75zZXYh8lYAylF3wM1VXRQuSc2yhpgqQpZnahmbU1s2Zm1lu5c5mF1tst6feSJprZN8ysq6QblTtslKRFkk7N347YTtItsXVXSlogaYKZ7WtmAyQNS2y/bZGff0v53n8v6RYza29mnSVdn3K9tBZJGmFmrc3sKOXuQNqb/27lvsV1L+cO87/ngcpYIWIc1UtVx5GZ3a7cUfU/O+fWl2u79cUYqpdqj6HmZtZKudN+zcysVfxI9uvUevu2c26Scv9wYyV9Kun/JD0k6WblztEWcr1ylfgj5c5RPilpWn6bsyU9Lek9SQslvZRYd5RyFwbXK3chrxIfrBOUOwT+H+UuXj5e5u3/u3LfNj5V7n0n/whuvKQnzWyjmV1Q28bM7DIzW1zLYj+S9LrLX3TMEsZRyao2jvK3+t6p3DWN5bFv9mPr8wbKhTFUsmp/Fl2h3HW7BySdkW8/WHSb+YtKAAAE0SCm+AEANF4UIgBAUBQiAEBQFCIAQFAUIgBAULXNNfe1zIxb7bKpxjnXKXQSaTGOssk512AeqcAYyqw6fRZxRNS41HdqEAAohzp9FlGIAABBUYgAAEFRiAAAQVGIAABBUYgAAEFRiAAAQVGIAABBUYgAAEGVNLMC0Bj9/Oc/9+LWrVt78bHHHhu1L7zwwqLbmjp1atSeP3++1/f44+V+7hnQsHFEBAAIikIEAAiKQgQACMqcq/vktcx4m1kLnXN9QyeRVhbG0dNPPx21a7vuU6rly5d78aBBg7x41apVFdlvqZh9O3uOOuooL166dKkX33DDDVH7gQceqEpOtajTZxFHRACAoChEAICguH0bTUr8VJxUt9Nx8dMhf/zjH72+7t27e/GwYcOido8ePby+Sy65xIvvvvvu1DmgaTr++OO9eM+ePV788ccfVzOdsuOICAAQFIUIABAUhQgAEBTXiNCo9e3r30F6/vnnF1z2gw8+8OJzzz3Xi2tqaqL2li1bvL59993Xi996662ofdxxx3l9HTp0KJIx8FW9e/f24q1bt3rx888/X810yo4jIgBAUBQiAEBQmTo1F7+V9qqrrvL6PvnkEy/esWNH1P7tb3/r9a1du9aLly1bVq4U0cAccsghXmzmTxoQPx131llneX1r1qxJvZ+bbrrJi3v16lVw2Zdffjn1dtF0HXPMMVH7uuuu8/oa2wzuHBEBAIKiEAEAgqIQAQCCytQ1okmTJkXtbt26pV7v6quv9uLNmzd7cfK23GqIT7kRf1+StGDBgmqn02S9+OKLXnzkkUd6cXysrF+/vuT9jBw50otbtGhR8rYASfrWt74Vtdu0aeP1Jaeqaug4IgIABEUhAgAERSECAASVqWtE8b8dOvbYY72+JUuWePG3v/3tqN2nTx+v7/TTT/fik046KWqvXr3a6zv88MNT57dr1y4vXrduXdRO/r1KXPIJnFwjCmflypVl2c6YMWO8OPkEzbi33367aAx8nbFjx0bt5LhtbJ8hHBEBAIKiEAEAgsrUqbk///nPX9v+Oq+++mrBvvbt23txfObahQsXen39+vVLnV98WiFJ+vvf/x61k6cODzjggKi9fPny1PtAdg0dOjRq33nnnV5fcvbtTz/9NGrfcsstXt+2bdsqkB0auuSfrMRnjo9/1khfnX27oeOICAAQFIUIABAUhQgAEFSmrhGVy4YNG7x4zpw5BZet7VpUMSNGjIjayetSf/3rX6N2Y5uOo6mKn7NPXhNKiv+bz507t2I5ofE47bTTCvbF/1SkMeKICAAQFIUIABAUhQgAEFSjvEZUKQceeKAXT5kyJWo3a+bX9PjfmdTn8QII54UXXvDiM888s+Cyjz32mBffdtttFckJjdd3vvOdgn3JR8k0NhwRAQCCohABAILi1FwdXHvttV7cqVOnqJ28Zfxvf/tbVXJC+SRnUO/fv78Xt2zZMmrX1NR4fXfddZcXb9mypczZobGJPxVAkq644govfvfdd6P27Nmzq5JTKBwRAQCCohABAIKiEAEAguIaURGnnHKKF//iF78ouOzw4cO9+P33369ITqicZ5991os7dOhQcNknnnjCi3nUB+pq0KBBXhx/dIzkP+om+QiaxoYjIgBAUBQiAEBQFCIAQFBcIypiyJAhXtyiRQsvjj9CYv78+VXJCeV17rnnRu0+ffoUXfa1116L2uPHj69USmgijjvuOC92znnx9OnTq5lOUBwRAQCCohABAILi1FxC69ato/bgwYO9vi+++MKL46dndu7cWdnEUBbJW7JvvfXWqJ089Zq0aNGiqM0UPijFwQcfHLUHDhzo9SWnBXv++eerklMWcEQEAAiKQgQACIpCBAAIimtECWPGjInaxx9/vNcXn3JDkt58882q5ITyuemmm7y4X79+BZdNPqGVW7ZRX5dffnnUTj7x+ZVXXqlyNtnBEREAICgKEQAgKAoRACCoJn+N6JxzzvHi22+/PWp//vnnXt+dd95ZlZxQOTfeeGPqZa+77jov5m+HUF9du3Yt2Ldhw4YqZpItHBEBAIKiEAEAgmpyp+aSU7z8+te/9uLmzZtH7ZkzZ3p9b731VuUSQ+Ykn5hZ6jROmzZtKrqd+NRC7dq1K7id/fff34vrcppx9+7dXnzzzTdH7W3btqXeDupn6NChBftefPHFKmaSLRwRAQCCohABAIKiEAEAgmoS14ji132S0/QcccQRXrx8+fKoHb+VG03Pe++9V5btPPPMM168Zs0aLz7ooIOi9sUXX1yWfdZm7dq1UXvixIlV2WdTNGDAAC+OPwYCX+KICAAQFIUIABBUkzg116NHj6h9wgknFF02fkts/DQdGofkLfnnnXdexfd50UUXlbzurl27ovaePXuKLjtjxoyovWDBgqLLvv766yXnhPTOP/98L45fJnj33Xe9vnnz5lUlpyziiAgAEBSFCAAQFIUIABBUo7xGlJzhdtasWQWXjT+RVZJeeumliuSEbLjgggu8eOzYsVE7PtVObY4++mgvrstt19OmTfPiFStWFFz22WefjdpLly5NvQ+Esd9++3nxkCFDCi47ffp0L05Ow9SUcEQEAAiKQgQACIpCBAAIqlFeIxo9erQXd+nSpeCyc+fO9WLnXEVyQjZNmjSpLNsZNWpUWbaDhi35iI/kU1fjf+t1//33VyWnhoAjIgBAUBQiAEBQjeLUXHKG2+uvvz5QJgCasuSpuf79+wfKpGHhiAgAEBSFCAAQFIUIABBUo7hGNHDgQC9u27ZtwWWTj3bYsmVLRXICAKTDEREAICgKEQAgKAoRACCoRnGNqDaLFy+O2t///ve9vvXr11c7HQBADEdEAICgKEQAgKCslNmmzYwpqrNpoXOub+gk0mIcZZNzzkLnkBZjKLPq9FnEEREAICgKEQAgKAoRACCoUm/frpG0spyJoCy6hk6gjhhH2cMYQjnUaRyVdLMCAADlwqk5AEBQFCIAQFAUIgBAUBQiAEBQFCIAQFAUIgBAUBQiAEBQFCIAQFAUIgBAUBQiAEBQFCIAQFAUIgBAUBQiAEBQDaIQmdkdZvZEhfdxupl9XMl91LL/QWa2ItT+mwLGEeqLMVQZqQqRmY00s7fNbKuZfZpv/8TMGsyz7UtlZl3MbEvsx+V/D3vjgSVsc5/8drqVMc9WZvaImX1uZmvM7IZybbtcGEfZH0exbXc0s8/M7LVyb7s+GEPZH0Nm9kMzm29m28zsT2nWqbUQmdlNku6XdK+kgyUdJOkaSadI2rfAOs1TZ51xzrlVzrm2e3/yLx8Xe+315DqB3v8vJXWT1EXSP0u61cwGBcjjazGOGsw42uteSR8E3P9XMIYazBj6TNJ9yv07pVK0EJlZO0l3SvqJc266c26zy3nXOXeJc+4f+eUeMbOpZjbTzLZKOsPM2pnZY2a2zsxWmtltZtYsv7x3eGtm3fJVeZ98fISZzTWzzWY2W1LHuv4mYtu8zMxWmVmNmY2L9bfO573BzD6U1K+u+4ht6wkzm2xmr+bf/0Aze8PMLo8t86+xb5fz8v/9IP9NZkRsubH539knZvajOqTxI0l3Ouc2OufelzRN0uXFV6kOxlHqfWVhHCn/zfqfJD1e6nspN8ZQ6n0FH0POuVnOuWckrUm7Tm2PCj9ZUktJf0ixrVGShkgaqty3k4cltZPUXVIHSbPyif1nim09KWm+pDMlnSjp5XgOZraxyLr3OOfuicUDJPWUdJSkv5jZc865JZLGS+qR/2kj6ZUUeRWz9/2/LalFLcueKmmnpKOdcyuk3HlZSZ0ltZZ0qKSzJT1lZi845z43s0sl/cw51ye5MTPrJOlASYtjLy+WNLhe76h8GEfpBRtH+fX3kfSAcl9i+tbzvZQTYyi9oGOoFLWdmusoqcY5t2vvC2b2ppltNLPtZnZqbNk/OOf+2zm3J//GLpZ0S/6bywpJ/yHp0toSMrMuyn0juN059w/n3DxJL8aXcc7tX+TnnsQmJzjntjvnFiv34Xxc/vUfSJronFvvnFst6de15VaL551z851ze/Z+OyvBDkl3Oed2OudmSPqHcoNWzrnHi/zD7z1M3xR7bZOkb5SYR7kxjtILOY4k6WeSXnfOLSpx35XCGEov9Biqs9oK0WeSOu49TM0n0d85t3++L77+6li7o3LfRFbGXlsp6bAUOR0qaYNzbmti3VKtjbW36csP7UPl51yffSixrVLVOOd2x+J4vsVsyf/3m7HXvilpcxlyKgfGUXrBxpGZHS7px5JuL0MO5cYYSi/kZ1FJaitE85WrhOel2JaLtWuU+ybSNfZaF0n/m29vlbRfrO/gWHuNpPZm1iaxbsT8O0eSP7emyHXvfg4vtI8SuERc7D0ml63fjp1bJ2mdvvyGpXw7KxebGUfpBRtHyp16OkTSUjNbq9yRQ/98OzTGUHohx1BJihYi59xGSRMkTTGzC82srZk1M7Peyp3LLLTebkm/lzTRzL5hZl0l3Shp70XBRZJOtdztiO0k3RJbd6WkBZImmNm+ZjZA0rDE9tsW+fm3lO/995JuMbP2ZtZZ0vUp10trkaQR+QuRR0m6Mpb/buW+xXUv4/4ek3S7me1vZr3y+3ukjNsvGeOoXqo5jl6UdISk3vmfCcr9DnuXafslYwzVS1U/i8ysuZm1Uu4ehGaW+9OSovcj1Hr7tnNuknL/cGMlfSrp/yQ9JOlmSW8WWfV65SrxR5LeUO6i37T8NmdLelrSe5IWSnopse4o5b6drVfuQt5jteVZggnKHQL/j3IXL8t9h9C/K/dt41Pl3nfyj+DGS3oyf477gto2Zrk7bhYXWeR25Q7JV0v6L0l3O+dS3cNfDYyjklVtHOWvg6zd+yPpc0lf5NvBMYZKVu3PoiskbVfuppcz8u0Hi27TuUwcmQEAmqgGMcUPAKDxohABAIKiEAEAgqIQAQCCohABAIKqba65r2Vm3GqXTTXOuU6hk0iLcZRNzrkG80gFxlBm1emziCOixqW+U4MAQDnU6bOIQgQACIpCBAAIikIEAAiKQgQACIpCBAAIikIEAAiKQgQACIpCBAAIikIEAAiKQgQACIpCBAAIikIEAAiqpNm3G5o2bdpE7Xvvvdfru/rqq7144cKFUfuiiy7y+lauZE5RACg3jogAAEFRiAAAQTWJU3OHHHJI1L7qqqu8vj179njxCSecELWHDh3q9U2ePLkC2SEr+vTp48XPPfecF3fr1q3iOZx55plevGTJkqi9evXqiu8f2TRs2DAvnjFjhhdfd911UfvBBx/0+nbv3l25xMqEIyIAQFAUIgBAUBQiAEBQjfIaUadOnbz40UcfDZQJGpKzzjrLi1u2bFn1HJLXAq688sqoPXLkyGqng4A6dOgQtadMmVJ02d/85jdRe9q0aV7f9u3by5tYBXBEBAAIikIEAAiqUZya++lPf+rFw4cP9+Lvfve7JW331FNP9eJmzfy6vXjx4qg9b968kvaBsPbZ58v/BYYMGRIwk5z4zB6SdOONN0bt+AwhkrR169aq5IQw4p8/nTt3LrrsU089FbV37NhRsZwqhSMiAEBQFCIAQFAUIgBAUI3iGtGvfvUrL05O21OqCy64oGgcn4374osv9vqS5/qRTWeccUbUPvnkk72+SZMmVTsdtW/f3ot79eoVtffbbz+vj2tEjUvyzwXGjRuXet3HH388ajvnypZTtXBEBAAIikIEAAiKQgQACMpKOZ9oZsFPQs6cOTNqn3322V5ffa4RffbZZ1F7y5YtXl/Xrl1Tb6d58+Yl51APC51zfUPsuBQhxtExxxzjxa+99lrUjv/bS/4jQaSvjodKiOcjSQMGDIja8ceZSNK6desqkoNzziqy4QrIwmdRufTt6/+v+8477xRcdteuXV7cokWLiuRUD3X6LOKICAAQFIUIABBUg7l9+7TTTvPinj17Ru3kqbi6nJpLPs1w1qxZUXvTpk1e3/e+9z0vLnZ75Y9//OOoPXXq1NT5oLJuu+02L45PmzN48GCvrxqn4iTpgAMOiNrJcV6uP0VA9o0YMSL1svHPqcaAIyIAQFAUIgBAUBQiAEBQmb1G1K1bNy/+3e9+58UdO3ZMva34VDzPPvus1zdhwgQv3rZtW6rtSNLo0aOjdvKpsPHpYVq1auX1xZ+mKEk7d+4suE/Uz4UXXujFyUc9LFu2LGovWLCgKjklxa81Jq8JxW/n3rhxY7VSQgDJx87EffHFF15cl+l/GgKOiAAAQVGIAABBUYgAAEFl9hpR/BHOUt2uCc2dO9eLR44cGbVrampKzil5jejuu++O2vfdd5/XF5+yP/k4gRkzZnjx8uXLS84JxV100UVenHyUwpQpU6qZjqSvXv+85JJLovbu3bu9vrvuuitqcy2xcenfv3/ROC75yI9FixZVJKdQOCICAARFIQIABJXZU3N1kbzt9sorr/Ti+pyOKyZ+ii1+ekWS+vXrV5F9onbt2rWL2ieddFLRZUNMvxS/7V/yTzsvWbLE65szZ05VckL11eUzorFPE8YREQAgKAoRACAoChEAIKgGc42oWbPCNfPEE0+sYiZfMvvyQZbJ/Irle8cdd3jxpZdeWta8mrqWLVtG7cMOO8zre+qpp6qdzlf06NGjYN/7779fxUwQUvKJrEnxKZ24RgQAQAVRiAAAQVGIAABBZfYa0TXXXOPFWXxk8rBhw6L28ccf7/XF803mnrxGhPLavHlz1E5OhXLsscd6cfwx3evXr69IPgceeKAXJx9NEffGG29UJAdkw4ABA6L2qFGjii67adOmqP3xxx9XLKcs4IgIABAUhQgAEFRmT83FT3uFknzqaq9evbz41ltvTbWddevWeTGzKFfW9u3bo3ZyZvMRI0Z48csvvxy1kzOo18Uxxxzjxd27d4/aydm2nXMFt5PFU9Aonw4dOkTtYn/iIUmzZ8+udDqZwRERACAoChEAICgKEQAgqMxeI8qCcePGefG1116bet0VK1ZE7csuu8zrW7VqVb3yQnrjx4/34vi0TJJ0zjnnRO36TP+TfNRI/DpQXZ4u/Mgjj5ScA7Kv2K378Sl9JOmhhx6qdDqZwRERACAoChEAICgKEQAgKK4RJcycOTNq9+zZs+TtfPjhh1GbaVvCWbp0qRf/4Ac/8OLevXtH7SOPPLLk/UyfPr1g36OPPurFycfKx8X/BgoNX+fOnb242LQ+yWl8FixYUJGcsogjIgBAUBQiAEBQmT01l7zNtth0GGeffXbRbT388MNR+9BDDy26bHw/9ZluJQtTFKF28dm5kzN1l8tHH32UetnkVEE8sbVh69+/vxcX+xx74YUXKp1OZnFEBAAIikIEAAiKQgQACCqz14imTp3qxZMmTSq47EsvveTFxa7t1OW6T12WffDBB1Mvi6Yleb0zGcdxTahxiT/2ISk5LdT9999f6XQyiyMiAEBQFCIAQFCZPTX33HPPefGYMWO8OPn01EpIPll1yZIlXjx69OiovWbNmorng4Yp+UTWYk9oReNy1llnFexLzsK/adOmSqeTWRwRAQCCohABAIKiEAEAgsrsNaKVK1d68ciRI714+PDhUfuGG26oSA4TJ0704smTJ1dkP2jcWrVqVbSfGbcbjxYtWnhxjx49Ci67Y8cOL965c2dFcmoIOCICAARFIQIABEUhAgAEldlrREnz5s0rGM+aNcvri/99j+Q/kmHGjBleX/wREZI//Ur8KatAqa644gov3rhxoxf/8pe/rGY6qKDktGDJp6zGH/OxbNmyquTUEHBEBAAIikIEAAiqwZyaK+bVV18tGgMhvfPOO1583333efGcOXOqmQ4qaPfu3V48btw4L45P77Rw4cKq5NQQcEQEAAiKQgQACIpCBAAIykqZkt7MmMc+mxY65/qGTiItxlE2OecKP0I2YxhDmVWnzyKOiAAAQVGIAABBUYgAAEFRiAAAQVGIAABBUYgAAEFRiAAAQVGIAABBUYgAAEFRiAAAQZX6GIgaSSvLmQjKomvoBOqIcZQ9jCGUQ53GUUlzzQEAUC6cmgMABEUhAgAERSECAARFIQIABEUhAgAERSECAARFIQIABEUhAgAERSECAAT1/72/dcXNZ0iqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Groud=nd Truth: {}\".format(example_target[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "\n",
    "        self.fc = nn.Linear(320,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.mp(self.conv1(x)))\n",
    "        x = F.relu(self.mp(self.conv2(x)))\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.log_softmax(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=320, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.5\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yakka\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.030699\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.004436\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.045343\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.010334\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.032033\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.005329\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.001703\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.011680\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.009198\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.016817\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.011694\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.005173\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.028331\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.007678\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.014712\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.033004\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.004983\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.011483\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.016285\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.012061\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.033261\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.048180\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.016026\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.013001\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.009468\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.007423\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.000931\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.003475\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.008613\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.003316\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.074704\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.010685\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.018067\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.048974\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.021349\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.011394\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.021261\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.067732\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.067245\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.004676\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.012797\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.045129\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.022926\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.133166\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.060116\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.047068\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.081498\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.051912\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.011298\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.017458\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.005371\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.009602\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.042140\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.003991\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.045011\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.006378\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.020430\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.007021\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.002045\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.051932\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.004598\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.047948\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.020172\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.014390\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.030254\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.004440\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.031152\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.065668\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.004624\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.012106\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.113505\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.001731\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.114061\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.037981\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.000733\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.107448\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.017583\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.076681\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.004491\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.005345\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.084729\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.007915\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.036257\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.074877\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.002831\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.011991\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.031447\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.016787\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.019620\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.102164\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.021992\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.008898\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.044732\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.036890\n",
      "\n",
      "Test set: Average loss: 0.0438, Accuracy: 9863/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.024536\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.057188\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.039967\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.003677\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.011647\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.007201\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.058196\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.030134\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.013208\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.017470\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.088701\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.042520\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.077405\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.045955\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.043992\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.029541\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.026694\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.001684\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.010429\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.013445\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.023756\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.021917\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.012919\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.059925\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.004790\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.021608\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.005811\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.009721\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.137068\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.080610\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.024755\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.017303\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.006812\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.040108\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.018868\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.012809\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.026226\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.028399\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.004764\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.196402\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.061833\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.012274\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.021516\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.020122\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.014085\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.108712\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.003425\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.022558\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.003179\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.054331\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.010443\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.008533\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.019062\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.054615\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.055480\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.028837\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.026756\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.008044\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.011856\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.017255\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.020016\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.061486\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.011833\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.018770\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.030013\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.023155\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.020745\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.044233\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.004483\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.016524\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.008362\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.093299\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.036089\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.054192\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.007255\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.040619\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.002003\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.008567\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.011085\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.026434\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.014119\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.029855\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.007824\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.006389\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.069126\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.007413\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.018293\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.028754\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.022477\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.081196\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.062970\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.010168\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.007652\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.021208\n",
      "\n",
      "Test set: Average loss: 0.0384, Accuracy: 9870/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.153086\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.006358\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.017148\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.051339\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.029224\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.033046\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.005628\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.029847\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.019835\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.080897\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.004764\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.006970\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.008556\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.006383\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.008464\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.018410\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.060897\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.096986\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.085831\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.008794\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.002426\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.131551\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.027702\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.013907\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.042349\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.026950\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.019331\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.018799\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.014423\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.002721\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.003696\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.012371\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.109242\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.017145\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.065331\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.017649\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.005467\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.011581\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.045898\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.010118\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.008354\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.022875\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.003221\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.009670\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.038591\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.111037\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.007177\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.010971\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.013636\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.037378\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.030563\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.043492\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.073220\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.073272\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.020304\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.007910\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.018491\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.002358\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.088404\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.075165\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.071583\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.034217\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.027446\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.047643\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.030746\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.019568\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.102664\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.027457\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.015091\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.058128\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.043562\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.058862\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.057646\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.048677\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.041809\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.015440\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.023785\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.011641\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.017034\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.005985\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.004649\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.026955\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.010105\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.017810\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.014659\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.464641\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.021377\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.056381\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.071134\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.022978\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.081272\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.134715\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.084199\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.031718\n",
      "\n",
      "Test set: Average loss: 0.0390, Accuracy: 9866/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001402\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.047263\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.007966\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.012106\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.019328\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.039643\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.018240\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.056849\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.009724\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.017867\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.004378\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.014202\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.083280\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.003770\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.002851\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.010189\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.025490\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.031091\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.145311\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.041105\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.013403\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.027747\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.040847\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.045628\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.026604\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.051027\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.021650\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.052526\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.017700\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.002837\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.009103\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.004022\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.011670\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.004128\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.003263\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.059817\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.005838\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.022816\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.068170\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.069549\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.041900\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.015656\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.049626\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.032167\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.003066\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.063627\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.015499\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.011587\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.015800\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.453644\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.019813\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.013148\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.051828\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.024126\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.028680\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.009230\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.002779\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.009870\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.032740\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.008664\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.081274\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.026206\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.062667\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.024541\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.007866\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.017442\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.014745\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.130267\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.014784\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.076775\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.011443\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.043769\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.022723\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.009196\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.016246\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.011514\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.120376\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.032897\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.005367\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.127246\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.032915\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.141597\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.029627\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.008937\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.000957\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.021775\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.080002\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.066288\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.022395\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.073339\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.015992\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.014624\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.002404\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.007281\n",
      "\n",
      "Test set: Average loss: 0.0381, Accuracy: 9870/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.009077\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.032156\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.002754\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.029571\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.014804\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.015069\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.011472\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.069725\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.003609\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.038443\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.018565\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.010605\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.009379\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.074828\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.035290\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.009789\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.015114\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.050341\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.044221\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.020781\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.009627\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.030547\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.018307\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.007350\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.015074\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.017306\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.005995\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.019559\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.010086\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.015076\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.081691\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.073762\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.050343\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.025850\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.009323\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.002229\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.068461\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.026121\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.011049\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.007958\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.003749\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.003441\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.020956\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.006210\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.031708\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.042331\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.023010\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.018334\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.007411\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.014980\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.018322\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.004752\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.002321\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.005864\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.111598\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.014280\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.032664\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.024352\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.090143\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.040236\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.040772\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.038538\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.096908\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.004317\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.004799\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.024483\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.091702\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.020285\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.002464\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.008016\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.044067\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.097176\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.040430\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.005906\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.046463\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.017124\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.138730\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.048607\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.004144\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.003883\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.030538\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.032575\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.010493\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.011596\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.034187\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.057164\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.001866\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.005567\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.005262\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.003881\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.015196\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.014483\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.040019\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.010240\n",
      "\n",
      "Test set: Average loss: 0.0360, Accuracy: 9880/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.008779\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.027903\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.014970\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.062154\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.011506\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.009874\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.017108\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.003029\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.002962\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.027090\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.114833\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.062283\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.109785\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.035567\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.009334\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.005873\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.008116\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.061605\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.007056\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.020440\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.022902\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.019204\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.035904\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.099109\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.028958\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.097132\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.001822\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.022960\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.025733\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.023740\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.067842\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.031629\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.011516\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.007796\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.019157\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.080684\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.001810\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.012901\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.034167\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.016241\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.015114\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.000851\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.081770\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.010925\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.015186\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.026735\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.011484\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.044033\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.002057\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.028924\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.032348\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.003222\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.016729\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.000770\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.022341\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.039593\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.049997\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.023573\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.003048\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.032389\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.038974\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.024767\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.090816\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.004789\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.010244\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.009199\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.017302\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.010881\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.012310\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.005757\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.030381\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.015156\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.030177\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.025497\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.002571\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.015672\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.023719\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.010737\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.015054\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.069147\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.020767\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.037992\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.026633\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.032773\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.021883\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.009169\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.072059\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.039346\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.036136\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.012926\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.014093\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.057778\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.005013\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.093889\n",
      "\n",
      "Test set: Average loss: 0.0416, Accuracy: 9868/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.026842\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.056814\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.011146\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.024760\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.003147\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.003586\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.031487\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.018362\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.030106\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.003173\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.056371\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.013601\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.043196\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.028787\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.079047\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.026916\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.065738\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.004249\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.043694\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.062918\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.025485\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.027017\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.018268\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.003690\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.035800\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.037245\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.067402\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.009998\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.048549\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.027716\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.006633\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.002670\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.015886\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.133639\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.077939\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.108323\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.010857\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.009409\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.020751\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.022013\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.023647\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.010572\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.011124\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.004042\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.005897\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.034347\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.009884\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.112836\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.008000\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.017015\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.021965\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.001732\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.023090\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.028651\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.100829\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.005949\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.022977\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.003779\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.024837\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.035595\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.008004\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.062788\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.016296\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.097778\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.007618\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.005352\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.020767\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.035004\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.009232\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.002353\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.002514\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.021262\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.078921\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.001414\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.004792\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.000632\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.004378\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.014454\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.004677\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.006917\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.012553\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.032984\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.090720\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.007513\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.005026\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.052746\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.057008\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.003098\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.147930\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.165652\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.121258\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.041124\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.026029\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.001659\n",
      "\n",
      "Test set: Average loss: 0.0378, Accuracy: 9867/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.058335\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.046897\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.011612\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.008837\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.002115\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.033005\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.003416\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.002752\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.006850\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.049078\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.005552\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.126672\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.029439\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.026642\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.012335\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.002405\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.057719\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.005787\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.016407\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.004107\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.025659\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.048907\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.025437\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.005519\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.011070\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.005160\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.013011\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.005884\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.013694\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.026952\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.032872\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.007612\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.109171\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.136548\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.025705\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.002996\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.028276\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.035584\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.025221\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.003536\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.170271\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.001990\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.029321\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.060708\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.100037\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.053720\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.487558\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.046043\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.003121\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.103640\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.015775\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.011790\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.047745\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.042889\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.052086\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.012966\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.086717\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.063260\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.026359\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.110935\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.003992\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.016937\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.003778\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.001848\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.055703\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.003714\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.007325\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.036028\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.033719\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.014200\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.002892\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.015011\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.071548\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.013447\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.003585\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.001595\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.011144\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.047646\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.029341\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.044757\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.040202\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.009576\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.008108\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.067727\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.006478\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.030347\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.029640\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.016852\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.008178\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.015831\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.007354\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.014631\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.005799\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.007380\n",
      "\n",
      "Test set: Average loss: 0.0364, Accuracy: 9878/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.162634\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.045600\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.019344\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.003599\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.012260\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.001036\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.008685\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.010829\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.012568\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.119437\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.004567\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.004784\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.050830\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.094092\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.005479\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.005139\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.015984\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.031441\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.022506\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.022157\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.020218\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.002816\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.008099\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.004061\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.003401\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.016461\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.012803\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.033152\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.007886\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.004773\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.007382\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.005876\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.015268\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.013176\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.054125\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.012303\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.005265\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.036503\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.002478\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.003280\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.004736\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.027698\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.014979\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.010504\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.002082\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.013730\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.020849\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.050165\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.012327\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.003785\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.023021\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.075001\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.002666\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.030199\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.002474\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.004732\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.013798\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.012402\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.108922\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.013045\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.047533\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.012429\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.005258\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.136382\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.035438\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.012427\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.010411\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.043613\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.028801\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.013012\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.005307\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.012349\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.025127\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.006650\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.000527\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.013040\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.011513\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.004985\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.023143\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.031333\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.090116\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.000586\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.008845\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.011458\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.003654\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.005092\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.036794\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.003847\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.045521\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.006726\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.079234\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.012856\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.004453\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.017309\n",
      "\n",
      "Test set: Average loss: 0.0397, Accuracy: 9872/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train() # tells the model that you are training\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = data, target\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        #print(loss.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data))\n",
    "        \n",
    "def test():\n",
    "    model.eval() # tells the model that you are training\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        ## Pytorcch variables depricated\n",
    "        data, target = data, target\n",
    "        output = model(data)\n",
    "        # sum up batch loss        \n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data\n",
    "        # get the index of max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "for epoch in range(1,10):\n",
    "    train(epoch)\n",
    "    test()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    plt.tight_layout()\n",
    "    print(example_data.shape)\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Groud=nd Truth: {}\".format(example_target[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n",
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2529e7a9f98>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(example_data[1][0].shape)\n",
    "print(example_data[0][0].shape)\n",
    "plt.imshow(example_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yakka\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-5.5313e-05, -5.7220e-06, -1.0548e-03, -4.3869e-05, -1.0490e-05,\n",
       "         -3.3188e-04, -2.2984e-04, -1.1385e-02, -8.5258e-04, -1.4734e-03,\n",
       "          0.0000e+00, -1.9073e-06, -1.6403e-04, -2.2888e-05, -1.6308e-04,\n",
       "         -8.2016e-05, -5.4541e-03, -9.1553e-05, -3.3302e-01, -1.9073e-06,\n",
       "         -2.6209e-02, -4.2095e-03, -1.9073e-06, -1.9073e-06, -8.1062e-05,\n",
       "         -1.9073e-05, -2.2888e-05,  0.0000e+00, -1.5831e-03, -7.1907e-04,\n",
       "          0.0000e+00, -2.4557e-03,  0.0000e+00, -4.7684e-05, -1.5068e-04,\n",
       "          0.0000e+00, -1.3691e-02, -5.1880e-04, -8.7738e-05, -7.4005e-04,\n",
       "         -1.9418e-02, -1.5365e-01, -1.3351e-05, -8.6498e-04, -4.6349e-04,\n",
       "         -4.6539e-04, -3.5667e-04,  0.0000e+00, -1.9073e-06, -5.7220e-06,\n",
       "         -1.2398e-05, -2.6703e-05, -7.6294e-06, -3.8147e-06,  0.0000e+00,\n",
       "         -4.3297e-04, -1.9073e-06, -2.9879e-03, -5.1498e-05, -6.8378e-04,\n",
       "          0.0000e+00, -8.5163e-04, -6.2672e-01, -2.2335e-03],\n",
       "        grad_fn=<MaxBackward0>),\n",
       " tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
       "         4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
       "         4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(example_data).max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
